{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On two ways to use determinantal point processes for Monte Carlo integration\n",
    "\n",
    "##### See the [documentation](https://dppy.readthedocs.io/en/latest/continuous_dpps/multivariate_jacobi_ope.html) on ReadTheDocs or the [paper](https://negative-dependence-in-ml-workshop.lids.mit.edu/wp-content/uploads/sites/29/2019/06/icml_camera_ready.pdf) at ICML'19 workshop on Negative Dependence in ML\n",
    "\n",
    "##### You can play with the different parameters :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Sampling\" data-toc-modified-id=\"Sampling-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Sampling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Minimal-working-example\" data-toc-modified-id=\"Minimal-working-example-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Minimal working example</a></span></li><li><span><a href=\"#Plot-a-sample-in-1D-or-2D\" data-toc-modified-id=\"Plot-a-sample-in-1D-or-2D-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Plot a sample in 1D or 2D</a></span></li><li><span><a href=\"#Timing\" data-toc-modified-id=\"Timing-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Timing</a></span></li></ul></li><li><span><a href=\"#Numerical-integration\" data-toc-modified-id=\"Numerical-integration-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Numerical integration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Estimators\" data-toc-modified-id=\"Estimators-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Estimators</a></span></li><li><span><a href=\"#Integrands\" data-toc-modified-id=\"Integrands-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Integrands</a></span></li><li><span><a href=\"#Estimation\" data-toc-modified-id=\"Estimation-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Estimation</a></span></li><li><span><a href=\"#Variance-decay\" data-toc-modified-id=\"Variance-decay-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Variance decay</a></span><ul class=\"toc-item\"><li><span><a href=\"#Of-an-integrand-$f$\" data-toc-modified-id=\"Of-an-integrand-$f$-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Of an integrand $f$</a></span></li><li><span><a href=\"#$f(x)-=-\\sum_{k=0}^{M-1}-\\frac{1}{k+1}-P_k(x)$\" data-toc-modified-id=\"$f(x)-=-\\sum_{k=0}^{M-1}-\\frac{1}{k+1}-P_k(x)$-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>$f(x) = \\sum_{k=0}^{M-1} \\frac{1}{k+1} P_k(x)$</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have not installed `DPPy` yet, you can install it with the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dppy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’£ **Note: to make sure you have the lastest version of the package please uncomment and run the following cell** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r DPPy\n",
    "# !git clone https://github.com/guilgautier/DPPy.git\n",
    "# !pip install scipy --upgrade\n",
    "# !pip install DPPy/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’£ If you have chosen to clone the repo and now wish to interact with the source code while running this notebook.\n",
    "You can uncomment the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# import os\n",
    "# import sys\n",
    "# sys.path.insert(0, os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.integrate import quad\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "from dppy.multivariate_jacobi_ope import MultivariateJacobiOPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal working example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, N = 2, 30  # dimension / number of points\n",
    "jac_params = 0.5 - np.random.rand(d, 2)  # Jacobi ensemble parameters\n",
    "\n",
    "dpp = MultivariateJacobiOPE(N, jac_params)\n",
    "dpp.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a sample in 1D or 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N, d = 300, 1\n",
    "    \n",
    "jac_params = 0.5 - np.random.rand(d, 2)\n",
    "\n",
    "dpp = MultivariateJacobiOPE(N, jac_params)\n",
    "\n",
    "sampl = dpp.sample()\n",
    "\n",
    "print('\\n'.join(['Display {} points in {}D'.format(dpp.N, dpp.dim),\n",
    "                 'with parameters i.i.d. uniformly on [-1/2, 1/2]^{}'.format(dpp.dim),\n",
    "                 '{}'.format(jac_params)]))\n",
    "\n",
    "dpp.plot(weighted=False)\n",
    "dpp.plot(weighted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, d = 300, 2\n",
    "    \n",
    "jac_params = 0.5 - np.random.rand(d, 2)\n",
    "\n",
    "dpp = MultivariateJacobiOPE(N, jac_params)\n",
    "\n",
    "sampl = dpp.sample()\n",
    "\n",
    "print('\\n'.join(['Display {} points in {}D'.format(dpp.N, dpp.dim),\n",
    "                 'with parameters i.i.d. uniformly on [-1/2, 1/2]^{}'.format(dpp.dim),\n",
    "                 '{}'.format(jac_params)]))\n",
    "\n",
    "dpp.plot(weighted=False)\n",
    "dpp.plot(weighted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a quick idea of the time to get a sample you can run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d, N = 2, 100\n",
    "jac_params = 0.5 - np.random.rand(d, 2)\n",
    "# jac_params = -0.5 * np.ones((d, 2))\n",
    "\n",
    "dpp = MultivariateJacobiOPE(N, jac_params)\n",
    "\n",
    "%timeit dpp.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BH_estimator(integrand, dpp, sample=None):\n",
    "    \n",
    "    if sample is not None:\n",
    "        return np.sum(integrand(sample).ravel() / dpp.K(sample))\n",
    "    \n",
    "    else:\n",
    "        sample = dpp.sample()\n",
    "        return BH_estimator(integrand, dpp, sample)\n",
    "\n",
    "def EZ_estimator(integrand, dpp, sample=None):\n",
    "\n",
    "    if sample is not None:\n",
    "        \n",
    "        phi_x = dpp.eval_poly_multiD(sample, normalize='norm')\n",
    "        integrand_x = integrand(sample).ravel()\n",
    "\n",
    "        EZ_estimator = np.linalg.solve(phi_x, integrand_x)[0]\n",
    "        EZ_estimator *= np.sqrt(dpp.mass_of_mu)\n",
    "        \n",
    "        return EZ_estimator#, np.linalg.cond(phi_sample)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        sample = dpp.sample()\n",
    "        return EZ_estimator(integrand, dpp, sample)\n",
    "\n",
    "def both_estimators(integrand, dpp, sample=None):\n",
    "    \n",
    "    if sample is not None:\n",
    "        return BH_estimator(integrand, dpp, sample), EZ_estimator(integrand, dpp, sample)\n",
    "    \n",
    "    else:\n",
    "        np.random.seed(None)\n",
    "        sample = dpp.sample()\n",
    "        return both_estimators(integrand, dpp, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bump_eps(X, eps=0.05):\n",
    "    \"\"\" https://en.wikipedia.org/wiki/Bump_function\n",
    "    \"\"\"\n",
    "\n",
    "    if type(X) is float:\n",
    "        f_x = np.exp(-1 / (1.0 - eps - X**2)) if abs(X) < 1 - eps else 0.\n",
    "        \n",
    "    elif X.ndim == 1:\n",
    "        in_I = np.abs(X) < 1 - eps\n",
    "        f_x = np.zeros(in_I.size)\n",
    "        f_x[in_I] = np.exp(-1 / (1.0 - eps - X[in_I]**2))\n",
    "\n",
    "    else:\n",
    "        in_I = np.all(np.abs(X) < 1 - eps, axis=1)\n",
    "        f_x = np.zeros(in_I.size)\n",
    "        f_x[in_I] = np.exp(-np.sum(1.0 / (1.0 - eps - X[in_I]**2), axis=1))\n",
    "    \n",
    "    return f_x\n",
    "\n",
    "def sine(X):\n",
    "\n",
    "    if type(X) is float: \n",
    "        f_x = np.sin(np.pi*X)\n",
    "    elif X.ndim == 1:\n",
    "        f_x = np.sin(np.pi*X)\n",
    "    else:\n",
    "        f_x = np.prod(np.sin(np.pi*X), axis=-1)\n",
    "    \n",
    "    return f_x\n",
    "\n",
    "def cosine(X):\n",
    "\n",
    "    if type(X) is float: \n",
    "        f_x = np.cos(np.pi*X)\n",
    "    elif X.ndim == 1:\n",
    "        f_x = np.cos(np.pi*X)\n",
    "    else:\n",
    "        f_x = np.prod(np.cos(np.pi*X), axis=-1)\n",
    "    \n",
    "    return f_x\n",
    "\n",
    "def absolute(X):\n",
    "    if type(X) is float: \n",
    "        f_x = np.abs(X)\n",
    "    elif X.ndim == 1:\n",
    "        f_x = np.abs(X)\n",
    "    else:\n",
    "        f_x = np.prod(np.abs(X), axis=-1)\n",
    "    \n",
    "    return f_x\n",
    "\n",
    "def heaviside(X, shift=0):\n",
    "    \n",
    "    if type(X) is float: \n",
    "        f_x = np.heaviside(X - shift, 0)\n",
    "    elif X.ndim == 1:\n",
    "        f_x = np.heaviside(X - shift, 0)\n",
    "    else:\n",
    "        f_x = np.prod(np.heaviside(X - shift, 0), axis=-1)\n",
    "    \n",
    "    return f_x\n",
    "\n",
    "def mix(X):\n",
    "    \n",
    "    return 0.5 * (heaviside(X) - 0.5) * (cosine(X) + cosine(2*X) + sine(5*X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrand(x):\n",
    "    return bump_eps(x, eps=0.05)\n",
    "#     return cosine(x)\n",
    "#     return 2 * (heaviside(x) - 0.5)\n",
    "#     return absolute(x)\n",
    "#     return mix(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, N = 1, 30\n",
    "\n",
    "jac_params = -0.5 + np.random.rand(d, 2)\n",
    "# jac_params = -0.5*np.ones((d, 2))\n",
    "\n",
    "dpp = MultivariateJacobiOPE(N, jac_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampl = dpp.sample()\n",
    "\n",
    "print('Estimation of the integral\\n')\n",
    "for lab, est in zip(['BH', 'EZ'], both_estimators(integrand, dpp, sampl)):\n",
    "    print(lab)\n",
    "    print(est)\n",
    "    \n",
    "if d == 1:\n",
    "    \n",
    "    print('scipy quad')\n",
    "    print(quad(lambda x: dpp.eval_w(x)*integrand(x), \n",
    "               -1, 1)[0])\n",
    "\n",
    "    tol = 1e-4\n",
    "    X_ = np.linspace(-1 + tol, 1 - tol, 300)[:, None]\n",
    "\n",
    "    print('numpy trapz')\n",
    "    print(np.trapz(dpp.eval_w(X_)*integrand(X_),\n",
    "                   X_.ravel()))\n",
    "    \n",
    "    \n",
    "    tols = np.zeros_like(dpp.jacobi_params)\n",
    "    tols[tols < 0] = 5e-2\n",
    "    X_ = np.linspace(-1 + tols[0, 1], 1 - tols[0, 0], 300)[:, None]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(X_, integrand(X_), label='f')\n",
    "    ax.scatter(sampl, np.zeros_like(sampl), label='sample')\n",
    "    ax.scatter(sampl, integrand(sampl), label='f(sample)')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(r'Base measure $\\propto (1-x)^a (1+x)^b$')\n",
    "    plt.plot(X_, 0.5*stats.beta(*(1+jac_params[0])).pdf(0.5*(1-X_)),\n",
    "             label='\\n'.join([r'$a \\approx {:1.3f}$'.format(jac_params[0, 0]),\n",
    "                              r'$b \\approx {:1.3f}$'.format(jac_params[0, 1])]))\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.legend(fontsize=15, loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Variance decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To repeat the estimations, we use the package `multiprocessing` \n",
    "##### In this notebook, to estimate the variance of both BH and EZ estimators,\n",
    "##### we draw $20$ samples with up to $N=100$ points for $d=1,2$ (by default)\n",
    "##### You can change the parameters, but sampling may take some time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Of an integrand $f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrand(x):\n",
    "    return bump_eps(x, eps=0.05)\n",
    "#     return cosine(x)\n",
    "#     return 2 * (heaviside(x) - 0.5)\n",
    "#     return absolute(x)\n",
    "#     return mix(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_max = 2\n",
    "nb_repeats = 20\n",
    "\n",
    "var_results = dict()\n",
    "\n",
    "for d in range(1, dim_max+1):\n",
    "    print('dimension =', d)\n",
    "    \n",
    "    jac_params = -0.5 + np.random.rand(d, 2)\n",
    "    jac_params[0, :] = -0.5\n",
    "    if d == 1:\n",
    "        N_min, N_max, N_step = 20, 100, 20\n",
    "    else:\n",
    "        N_min, N_max, N_step = 20, 100, 20\n",
    "    \n",
    "    var_results[(d,)] = jac_params\n",
    "    \n",
    "    for N in range(N_min, N_max+1, N_step):\n",
    "        print('#points =', N)\n",
    "\n",
    "        dpp = MultivariateJacobiOPE(N, jac_params)\n",
    "\n",
    "        pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "        results = pool.starmap(both_estimators, [(integrand, dpp) for _ in range(nb_repeats)])\n",
    "        results = np.array(results)\n",
    "        var_results[(d, N)] = np.var(results, axis=0)\n",
    "\n",
    "        pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_par = {d: var_results.get((d, )) for d in range(1, dim_max + 1)}\n",
    "var_N = {d: np.array([key[1] for key in var_results.keys() if len(key)==2 and key[0]==d])\n",
    "            for d in range(1, dim_max + 1)}\n",
    "var_res = {d: np.array([value for key, value in var_results.items() if len(key)==2 and key[0]==d]).T\n",
    "            for d in range(1, dim_max + 1)}\n",
    "\n",
    "cols = ['blue', 'green']\n",
    "CB_cols = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "markers = ['o', '^']\n",
    "labels = ['BH', 'EZ']\n",
    "for d in range(1, dim_max + 1):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "#     plt.title(r'Dimension $d={}$'.format(d), fontsize=20)\n",
    "    ax.set_xlabel(r'$N$', fontsize=22)\n",
    "    ax.xaxis.set_label_coords(0.98, -0.025)\n",
    "    ax.set_ylabel(r'$\\mathrm{\\mathbb{V}}$ar', fontsize=22, rotation='horizontal')\n",
    "    ax.yaxis.set_label_coords(-0.06, 0.94)\n",
    "    ax.tick_params(axis = 'both', which = 'major', labelsize = 17.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "    for c, m, lab, var_estim in zip(CB_cols[:2], markers, labels, var_res[d]):\n",
    "\n",
    "        ax.loglog(var_N[d], var_estim, m, c=c, markersize=8)\n",
    "\n",
    "        x_plot = np.array([np.min(var_N[d]), np.max(var_N[d])])\n",
    "        \n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(np.log(var_N[d]), np.log(var_estim))\n",
    "        lab += r' {:.1f}, {:.2f}'.format(slope, r_value**2)\n",
    "        \n",
    "        ax.loglog(x_plot, np.exp(intercept)*x_plot**slope, c=c, label=lab)\n",
    "    \n",
    "    leg = ax.legend(fontsize=20, frameon=False, handlelength=0.6, loc='lower left')\n",
    "\n",
    "    for line in leg.get_lines():\n",
    "        line.set_linewidth(4.0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $f(x) = \\sum_{k=0}^{M-1} \\frac{1}{k+1} P_k(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$M=70$\n",
    "\n",
    "EZ provides perfect estimation when $N\\geq M$, see the drop in the variance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_max = 2\n",
    "nb_repeats = 20\n",
    "\n",
    "M = 70\n",
    "N_min, N_max, N_step = 10, 100, 10\n",
    "\n",
    "var_results = dict()\n",
    "\n",
    "for d in range(1, dim_max+1):\n",
    "    print('dimension =', d)\n",
    "    \n",
    "    jac_params = -0.5 + np.random.rand(d, 2)\n",
    "    jac_params[0, :] = -0.5\n",
    "    \n",
    "    dpp_gp = MultivariateJacobiOPE(M, jac_params)\n",
    "    coefs = 1.0 / np.arange(1, dpp_gp.N + 1)\n",
    "    \n",
    "    def f_gp(X):\n",
    "        return np.sum(coefs*dpp_gp.eval_poly_multiD(X, normalize='norm'), axis=-1)\n",
    "\n",
    "    var_results[(d, )] = jac_params\n",
    "    \n",
    "    for N in range(N_min, N_max+1, N_step):\n",
    "        print('#points =', N)\n",
    "\n",
    "        dpp = MultivariateJacobiOPE(N, jac_params)\n",
    "\n",
    "        pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "        results = pool.starmap(both_estimators, [(f_gp, dpp) for _ in range(nb_repeats)])\n",
    "        results = np.array(results)\n",
    "        var_results[(d, N)] = np.var(results, axis=0)\n",
    "\n",
    "        pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_par = {d: var_results.get((d, )) for d in range(1, dim_max + 1)}\n",
    "var_N = {d: np.array([key[1] for key in var_results.keys() if len(key)==2 and key[0]==d])\n",
    "            for d in range(1, dim_max + 1)}\n",
    "var_res = {d: np.array([value for key, value in var_results.items() if len(key)==2 and key[0]==d]).T\n",
    "            for d in range(1, dim_max + 1)}\n",
    "\n",
    "\n",
    "CB_cols = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "markers = ['o', '^']\n",
    "labels = ['BH', 'EZ']\n",
    "for d in range(1, dim_max + 1):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(r'Dimension $d={}$, $M$ = {}'.format(d, M), fontsize=20)\n",
    "    ax.set_xlabel(r'$N$', fontsize=22)\n",
    "    ax.xaxis.set_label_coords(1.03, -0.0)\n",
    "    ax.set_ylabel(r'$\\mathrm{\\mathbb{V}}$ar', fontsize=22, rotation='horizontal')\n",
    "    ax.yaxis.set_label_coords(-0.06, 0.95)\n",
    "    ax.tick_params(axis = 'both', which = 'major', labelsize = 17.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    for c, m, lab, var_estim in zip(CB_cols[:2], markers, labels, var_res[d]):\n",
    "\n",
    "        ax.loglog(var_N[d], var_estim, m, c=c, markersize=8)\n",
    "\n",
    "        x_plot = np.array([np.min(var_N[d]), np.max(var_N[d])])\n",
    "        \n",
    "        if lab == 'BH':\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(np.log(var_N[d]), np.log(var_estim))\n",
    "            lab += r' {:.1f}, {:.2f}'.format(slope, r_value**2)\n",
    "        \n",
    "            ax.loglog(x_plot, np.exp(intercept)*x_plot**slope, c=c, label=lab)\n",
    "        \n",
    "    leg = ax.legend(fontsize=20, frameon=False, handlelength=0.6, loc='lower left')\n",
    "\n",
    "    for line in leg.get_lines():\n",
    "        line.set_linewidth(4.0)\n",
    "        \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "171px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
