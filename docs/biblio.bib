@inproceedings{AnGhRe16,
	Author = {Anari, N and Gharan, S O and Rezaei, A},
	Booktitle = {Conference on Learning Theory},
	Date-Modified = {2017-05-03 17:02:33 +0000},
	Pages = {23--26},
	Title = {{Monte-Carlo Markov chain algorithms for sampling strongly Rayleigh distributions and determinantal point processes}},
	Year = {2016}}

@inproceedings{AfKuFo13,
abstract = {Determinantal point processes (DPPs) are appealing models for subset selection prob-lems where diversity is desired. They offer surprisingly efficient inference, including sam-pling in O(N 3) time and O(N 2) space, where N is the number of base items. However, in some applications, N may grow so large that sampling from a DPP becomes compu-tationally infeasible. This is especially true in settings where the DPP kernel matrix can-not be represented by a linear decomposition of low-dimensional feature vectors. In these cases, we propose applying the Nystr{\"{o}}m ap-proximation to project the kernel matrix into a low-dimensional space. While theoretical guarantees for the Nystr{\"{o}}m approximation in terms of standard matrix norms have been previously established, we are concerned with probabilistic measures, like total variation dis-tance between the DPP and its Nystr{\"{o}}m ap-proximation, that behave quite differently. In this paper we derive new error bounds for the Nystr{\"{o}}m-approximated DPP and present em-pirical results to corroborate them. We then demonstrate the Nystr{\"{o}}m-approximated DPP by applying it to a motion capture summa-rization task.},
address = {Scottsdale, AZ, USA},
author = {Affandi, Raja Hafiz and Kulesza, Alex and Fox, Emily B and Taskar, Ben},
booktitle = {International Conference on Artificial Intelligence and Statistics},
file = {:Users/ggautier/Documents/Mendeley Desktop/Affandi et al. - 2013 - Nystrom Approximation for Large-Scale Determinantal Processes.pdf:pdf},
issn = {15337928},
keywords = {dblp},
pages = {85--98},
title = {{Nystrom Approximation for Large-Scale Determinantal Processes.}},
url = {http://jmlr.org/proceedings/papers/v31/affandi13a.html},
volume = {31},
year = {2013}
}
@article{AvGa13,
abstract = {Consider a finite weighted oriented graph. We study a probability measure on the set of spanning rooted oriented forests on the graph. We prove that the set of roots sampled from this measure is a determinantal process, characterized by a possibly non-symmetric kernel with complex eigenvalues. We then derive several results relating this measure to the Markov process associated with the starting graph, to the spectrum of its generator and to hitting times of subsets of the graph. In particular, the mean hitting time of the set of roots turns out to be independent of the starting point, conditioning or not to a given number of roots. Wilson's algorithm provides a way to sample this measure and, in absence of complex eigenvalues of the generator, we explain how to get samples with a number of roots approximating a prescribed integer. We also exploit the properties of this measure to give some probabilistic insight into the proof of an algebraic result due to Micchelli and Willoughby [13]. Further, we present two different related coalescence and fragmentation processes.},
author = {Avena, L and Gaudilli{\`e}re, A},
file = {:Users/ggautier/Documents/Mendeley Desktop/Avena, Gaudilli{\`e}re - 2013 - On some random forests with determinantal roots.pdf:pdf},
journal = {e-prints},
keywords = {05C81,05C85 Keywords,15A15,15A18,60J20,Finite networks,MSC 2010,Wilson's algorithm,coalescence and frag-mentation,determinantal processes,hit-ting times,local equilibria,primary,random partitions,random sets,secondary,spanning forests},
title = {{On some random forests with determinantal roots}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.740.6173{\&}rep=rep1{\&}type=pdf},
year = {2013}
}
@article{BaHa16,
abstract = {We show that repulsive random variables can yield Monte Carlo methods with faster convergence rates than the typical {\$}N{\^{}}{\{}-1/2{\}}{\$}, where {\$}N{\$} is the number of integrand evaluations. More precisely, we propose stochastic numerical quadratures involving determinantal point processes associated with multivariate orthogonal polynomials, and we obtain root mean square errors that decrease as {\$}N{\^{}}{\{}-(1+1/d)/2{\}}{\$}, where {\$}d{\$} is the dimension of the ambient space. First, we prove a central limit theorem (CLT) for the linear statistics of a class of determinantal point processes, when the reference measure is a product measure supported on a hypercube, which satisfies the Nevai-class regularity condition, a result which may be of independent interest. Next, we introduce a Monte Carlo method based on these determinantal point processes, and prove a CLT with explicit limiting variance for the quadrature error, when the reference measure satisfies a stronger regularity condition. As a corollary, by taking a specific reference measure and using a construction similar to importance sampling, we obtain a general Monte Carlo method, which applies to any measure with continuously derivable density. Loosely speaking, our method can be interpreted as a stochastic counterpart to Gaussian quadrature, which, at the price of some convergence rate, is easily generalizable to any dimension and has a more explicit error term.},
archivePrefix = {arXiv},
arxivId = {1605.00361},
author = {Bardenet, R{\'e}mi and Hardy, Adrien},
eprint = {1605.00361},
file = {:Users/ggautier/Documents/Mendeley Desktop/Bardenet, Hardy - 2016 - Monte Carlo with Determinantal Point Processes.pdf:pdf},
journal = {ArXiv e-prints},
title = {{Monte Carlo with Determinantal Point Processes}},
url = {http://arxiv.org/abs/1605.00361},
year = {2016}
}
@inproceedings{GaBaVa17,
abstract = {Determinantal point processes (DPPs) are distributions over sets of items that model diversity using kernels. Their applications in machine learning include summary extraction and recommendation systems. Yet, the cost of sampling from a DPP is prohibitive in large-scale applications, which has triggered an effort towards efficient approximate samplers. We build a novel MCMC sampler that combines ideas from combinatorial geometry, linear programming, and Monte Carlo methods to sample from DPPs with a fixed sample cardinality, also called projection DPPs. Our sampler leverages the ability of the hit-and-run MCMC kernel to efficiently move across convex bodies. Previous theoretical results yield a fast mixing time of our chain when targeting a distribution that is close to a projection DPP, but not a DPP in general. Our empirical results demonstrate that this extends to sampling projection DPPs, i.e., our sampler is more sample-efficient than previous approaches which in turn translates to faster convergence when dealing with costly-to-evaluate functions, such as summary extraction in our experiments.},
address = {Sydney, Australia},
archivePrefix = {arXiv},
arxivId = {1705.10498},
author = {Gautier, Guillaume and Bardenet, R{\'e}mi and Valko, Michal},
booktitle = {International Conference on Machine Learning},
editor = {Precup, Doina and Teh, Yee Whye},
eprint = {1705.10498},
file = {:Users/ggautier/Documents/Mendeley Desktop/Gautier, Bardenet, Valko - 2017 - Zonotope hit-and-run for efficient sampling from projection DPPs.pdf:pdf},
pages = {1223--1232},
publisher = {PMLR},
title = {{Zonotope hit-and-run for efficient sampling from projection DPPs}},
url = {http://proceedings.mlr.press/v70/gautier17a/gautier17a.pdf http://arxiv.org/abs/1705.10498},
year = {2017}
}


@article{Gil14,
Author = {Gillenwater, Jennifer Ann},
Journal = {Publicly Accessible Penn Dissertations. 1285.},
Title = {{Approximate inference for determinantal point processes}},
url = {https://repository.upenn.edu/edissertations/1285},
Year = {2014}}

@article{HKPV06,
Author = {Hough, J B and Krishnapur, M and Peres, Y and Virag, B},
Journal = {Probability surveys},
Title = {{Determinantal processes and independence}},
Year = {2006}}

@article{KuTa12,
abstract = {Determinantal point processes (DPPs) are elegant probabilistic models of repulsion that arise in quantum physics and random matrix theory. In contrast to traditional structured models like Markov random fields, which become intractable and hard to approximate in the presence of negative correlations, DPPs offer efficient and exact algorithms for sampling, marginalization, conditioning, and other inference tasks. We provide a gentle introduction to DPPs, focusing on the intuitions, algorithms, and extensions that are most relevant to the machine learning community, and show how DPPs can be applied to real-world applications like finding diverse sets of high-quality search results, building informative summaries by selecting diverse sentences from documents, modeling non-overlapping human poses in images or video, and automatically building timelines of important news stories.},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1207.6083},
author = {Kulesza, Alex and Taskar, Ben},
doi = {10.1561/2200000044},
eprint = {1207.6083},
file = {:Users/ggautier/Documents/Mendeley Desktop/Kulesza - 2012 - Determinantal Point Processes for Machine Learning.pdf:pdf},
issn = {1935-8237},
journal = {Foundations and Trends in Machine Learning},
month = {jul},
number = {2-3},
pages = {123--286},
title = {{Determinantal Point Processes for Machine Learning}},
url = {http://arxiv.org/abs/1207.6083},
volume = {5},
year = {2012}
}
@article{LaMoRu15,
abstract = {Statistical models and methods for determinantal point processes (DPPs) seem largely unexplored. We demonstrate that DPPs provide useful models for the description of spatial point pattern datasets where nearby points repel each other. Such data are usually modelled by Gibbs point processes, where the likelihood and moment expressions are intractable and simulations are time consuming. We exploit the appealing probabilistic properties of DPPs to develop parametric models, where the likelihood and moment expressions can be easily evaluated and realizations can be quickly simulated. We discuss how statistical inference is conducted using the likelihood or moment properties of DPP models, and we provide freely available software for simulation and statistical inference.},
archivePrefix = {arXiv},
arxivId = {1205.4818},
author = {Lavancier, Fr{\'e}d{\'e}ric and M{\o}ller, Jesper and Rubak, Ege},
doi = {10.1111/rssb.12096},
eprint = {1205.4818},
file = {:Users/ggautier/Documents/Mendeley Desktop/Lavancier, M{\o}ller, Rubak - 2015 - Determinantal point process models and statistical inference.pdf:pdf},
issn = {14679868},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Maximum-likelihood-based inference,Point process density,Product densities,Repulsiveness,Simulation,Spectral approach},
number = {4},
pages = {853--877},
title = {{Determinantal point process models and statistical inference}},
volume = {77},
year = {2015}
}
@inproceedings{LiJeSr17,
abstract = {We study dual volume sampling, a method for selecting k columns from an n*m short and wide matrix (n {\textless}= k {\textless}= m) such that the probability of selection is proportional to the volume of the parallelepiped spanned by the rows of the induced submatrix. This method was studied in [3], who motivated it as a promising method for column subset selection. However, the development of polynomial time sampling algorithms -- exact or approximate -- has been since open. We close this open problem by presenting (i) an exact (randomized) polynomial time sampling algorithm; (ii) its derandomization that samples subsets satisfying the desired properties deterministically; and (iii) an efficient approximate sampling procedure using Markov chains that are provably fast mixing. Our algorithms can thus benefit downstream applications of dual volume sampling, such as column subset selection and experimental design.},
address = {Long Beach, CA, USA},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1703.02674},
author = {Li, Chengtao and Jegelka, Stefanie and Sra, Suvrit},
booktitle = {Neural Information Processing Systems},
eprint = {1703.02674},
file = {:Users/ggautier/Documents/Mendeley Desktop/Li, Jegelka, Sra - 2017 - Column Subset Selection via Polynomial Time Dual Volume Sampling.pdf:pdf},
month = {mar},
title = {{Column Subset Selection via Polynomial Time Dual Volume Sampling}},
url = {http://arxiv.org/abs/1703.02674},
year = {2017}
}
@inproceedings{LiJeSr16a,
abstract = {Determinantal Point Processes (DPPs) provide probabilistic models over discrete sets of items that help model repulsion and diversity. Applicability of DPPs to large sets of data is, however, hindered by the expensive matrix operations involved, especially when sampling. We therefore propose a new efficient approximate two-stage sampling algorithm for discrete k-DPPs. As opposed to previous approximations, our algorithm aims at minimizing the variational distance to the original distribution. Experiments indicate that the resulting sampling algorithm works well on large data and yields more accurate samples than previous approaches.},
address = {Cadiz, Spain},
archivePrefix = {arXiv},
arxivId = {1509.01618},
author = {Li, Chengtao and Jegelka, Stefanie and Sra, Suvrit},
booktitle = {International Conference on Artificial Intelligence and Statistics},
eprint = {1509.01618},
file = {:Users/ggautier/Documents/Mendeley Desktop/Li, Jegelka, Sra - Unknown - Efficient Sampling for k-Determinantal Point Processes.pdf:pdf},
pages = {1--14},
title = {{Efficient Sampling for k-Determinantal Point Processes}},
url = {http://proceedings.mlr.press/v51/li16f.pdf http://arxiv.org/abs/1509.01618},
volume = {51},
year = {2016}
}
@inproceedings{LiJeSr16b,
abstract = {The Nystr$\backslash$"om method has long been popular for scaling up kernel methods. Its theoretical guarantees and empirical performance rely critically on the quality of the landmarks selected. We study landmark selection for Nystr$\backslash$"om using Determinantal Point Processes (DPPs), discrete probability models that allow tractable generation of diverse samples. We prove that landmarks selected via DPPs guarantee bounds on approximation errors; subsequently, we analyze implications for kernel ridge regression. Contrary to prior reservations due to cubic complexity of DPPsampling, we show that (under certain conditions) Markov chain DPP sampling requires only linear time in the size of the data. We present several empirical results that support our theoretical analysis, and demonstrate the superior performance of DPP-based landmark selection compared with existing approaches.},
address = {New York, USA},
archivePrefix = {arXiv},
arxivId = {1603.06052},
author = {Li, Chengtao and Jegelka, Stefanie and Sra, Suvrit},
booktitle = {International Conference on Machine Learning},
eprint = {1603.06052},
file = {:Users/ggautier/Documents/Mendeley Desktop/Li, Jegelka, Sra - Unknown - Fast DPP Sampling for Nystr{\"{o}}m with Application to Kernel Methods.pdf:pdf},
isbn = {9781510829008},
pages = {2061----2070},
title = {{Fast DPP Sampling for Nystr$\backslash$"om with Application to Kernel Methods}},
url = {http://proceedings.mlr.press/v48/lih16.html http://arxiv.org/abs/1603.06052},
volume = {48},
year = {2016}
}
@inproceedings{LiJeSr16c,
abstract = {We study probability measures induced by set functions with constraints. Such measures arise in a variety of real-world settings, where prior knowledge, resource limitations, or other pragmatic considerations impose constraints. We consider the task of rapidly sampling from such constrained measures, and develop fast Markov chain samplers for them. Our first main result is for MCMC sampling from Strongly Rayleigh (SR) measures, for which we present sharp polynomial bounds on the mixing time. As a corollary, this result yields a fast mixing sampler for Determinantal Point Processes (DPPs), yielding (to our knowledge) the first provably fast MCMC sampler for DPPs since their inception over four decades ago. Beyond SR measures, we develop MCMC samplers for probabilistic models with hard constraints and identify sufficient conditions under which their chains mix rapidly. We illustrate our claims by empirically verifying the dependence of mixing times on the key factors governing our theoretical bounds.},
address = {Barcelona, Spain},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1608.01008},
author = {Li, Chengtao and Jegelka, Stefanie and Sra, Suvrit},
booktitle = {Neural Information Processing Systems},
eprint = {1608.01008},
file = {:Users/ggautier/Documents/Mendeley Desktop/Li, Jegelka - 2016 - Fast Mixing Markov Chains for Strongly Rayleigh Measures , DPPs , and Constrained Sampling.pdf:pdf},
issn = {10495258},
number = {2},
title = {{Fast Mixing Markov Chains for Strongly Rayleigh Measures, DPPs, and Constrained Sampling}},
url = {https://papers.nips.cc/paper/6182-fast-mixing-markov-chains-for-strongly-rayleigh-measures-dpps-and-constrained-sampling http://arxiv.org/abs/1608.01008},
year = {2016}
}
@article{LiJeSr16d,
abstract = {In this note we consider sampling from (non-homogeneous) strongly Rayleigh probability measures. As an important corollary, we obtain a fast mixing Markov Chain sampler for Determinantal Point Processes.},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1607.03559},
author = {Li, Chengtao and Jegelka, Stefanie and Sra, Suvrit},
eprint = {1607.03559},
file = {:Users/ggautier/Documents/Mendeley Desktop/Li, Jegelka, Sra - 2016 - Fast Sampling for Strongly Rayleigh Measures with Application to Determinantal Point Processes.pdf:pdf},
journal = {ArXiv e-prints},
title = {{Fast Sampling for Strongly Rayleigh Measures with Application to Determinantal Point Processes}},
url = {http://arxiv.org/abs/1607.03559},
year = {2016}
}
@article{TrAmBa17a,
abstract = {We present a new random sampling strategy for k-bandlimited signals defined on graphs, based on determinantal point processes (DPP). For small graphs, ie, in cases where the spectrum of the graph is accessible, we exhibit a DPP sampling scheme that enables perfect recovery of bandlimited signals. For large graphs, ie, in cases where the graph's spectrum is not accessible, we investigate, both theoretically and empirically, a sub-optimal but much faster DPP based on loop-erased random walks on the graph. Preliminary experiments show promising results especially in cases where the number of measurements should stay as small as possible and for graphs that have a strong community structure. Our sampling scheme is efficient and can be applied to graphs with up to {\$}10{\^{}}6{\$} nodes.},
archivePrefix = {arXiv},
arxivId = {1703.01594},
author = {Tremblay, Nicolas and Amblard, Pierre-Olivier and Barthelm{\'e}, Simon},
eprint = {1703.01594},
file = {:Users/ggautier/Documents/Mendeley Desktop/Tremblay, Amblard, Barthelm{\'e} - 2017 - Graph sampling with determinantal processes.pdf:pdf},
isbn = {9780992862671},
journal = {ArXiv e-prints},
title = {{Graph sampling with determinantal processes}},
url = {http://arxiv.org/abs/1703.01594},
year = {2017}
}
@inproceedings{TrBaAm17b,
abstract = {R{\'e}sum{\'e} – Nous consid{\'e}rons l echantillonnage de signaux sur graph{\`e} a bande limit{\'e}e k , i . e . , les combinaisons lin{\'e}aires des k premiers modes de Fourier du graphe . Il existe k noeuds du graphe qui permettent leur reconstruction parfaite , les trouver n{\'e}cessite cependant une diagonalisation partielle de la matrice laplacienne , trop co{\^{u}}teus{\`e} a grande dimension . Nous proposons une nouvelle m{\'e}thode rapide d echantillonnage bas{\'e}e sur des processus d{\'e}terminantaux qui permet la reconstructio a partir d ' un nombre d echantillons de l ' ordre de k . Abstract – We consider the problem of sampling k - bandlimited graph signals , i . e . , linear combinations of the first k graph Fourier modes . We know that a set of k nodes embedding all k - bandlimited signals always exists , thereby enabling their perfect reconstruction after sampling . Unfortunately , to exhibit such a set , one needs to partially diagonalize the graph Laplacian , which becomes prohibitive at large scale . We propose a novel strategy based on determinantal point processes that side - steps partial diagonalisation and enables reconstruction with only O (k) samples .},
archivePrefix = {arXiv},
arxivId = {1704.02239},
author = {Tremblay, Nicolas and Barthelme, Simon and Amblard, Pierre-Olivier},
booktitle = {GRETSI},
eprint = {1704.02239},
file = {:Users/ggautier/Documents/Mendeley Desktop/Tremblay, Barthel, Amblard - Unknown - {\'{E}}chantillonnage de signaux sur graphes via des processus d{\'e}terminantaux.pdf:pdf},
title = {{{\'{E}}chantillonnage de signaux sur graphes via des processus d{\'e}terminantaux}},
url = {https://hal.archives-ouvertes.fr/hal-01503736 https://arxiv.org/abs/1704.02239},
year = {2017}
}
@ARTICLE{TrBaAm18,
   author = {Tremblay, Nicolas and Barthelme, Simon and Amblard, Pierre-Olivier},
    title = "{Optimized Algorithms to Sample Determinantal Point Processes}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1802.08471},
 primaryClass = "stat.CO",
 keywords = {Statistics - Computation, Computer Science - Learning, Statistics - Machine Learning},
     year = 2018,
    month = feb,
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180208471T},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
