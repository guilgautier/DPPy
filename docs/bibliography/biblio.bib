@inproceedings{AKFT13,
abstract = {Determinantal point processes (DPPs) are appealing models for subset selection prob-lems where diversity is desired. They offer surprisingly efficient inference, including sam-pling in O(N 3) time and O(N 2) space, where N is the number of base items. However, in some applications, N may grow so large that sampling from a DPP becomes compu-tationally infeasible. This is especially true in settings where the DPP kernel matrix can-not be represented by a linear decomposition of low-dimensional feature vectors. In these cases, we propose applying the Nystr{\"{o}}m ap-proximation to project the kernel matrix into a low-dimensional space. While theoretical guarantees for the Nystr{\"{o}}m approximation in terms of standard matrix norms have been previously established, we are concerned with probabilistic measures, like total variation dis-tance between the DPP and its Nystr{\"{o}}m ap-proximation, that behave quite differently. In this paper we derive new error bounds for the Nystr{\"{o}}m-approximated DPP and present em-pirical results to corroborate them. We then demonstrate the Nystr{\"{o}}m-approximated DPP by applying it to a motion capture summa-rization task.},
author = {Affandi, Raja Hafiz and Kulesza, Alex and Fox, Emily B and Taskar, Ben},
booktitle = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
file = {:Users/ggautier/Documents/Mendeley Desktop/Affandi et al. - Unknown - Nystr{\"{o}}m Approximation for Large-Scale Determinantal Processes.pdf:pdf},
issn = {15337928},
keywords = {dblp},
pages = {85--98},
title = {{Nystr{\"{o}}m Approximation for Large-Scale Determinantal Processes}},
url = {http://proceedings.mlr.press/v31/affandi13a},
volume = {31},
year = {2013}
}
@article{Ald90,
abstract = {A random walk on a finite graph can be used to construct a uniform random spanning tree. We show how random walk techniques can be applied to the study of several properties of the uniform random spanning tree: the proportion of leaves, the distribution of degrees, and the diameter.},
annote = {NULL},
author = {Aldous, David J},
doi = {10.1137/0403039},
file = {:Users/ggautier/Documents/Mendeley Desktop/Aldous - 1990 - The Random Walk Construction of Uniform Spanning Trees and Uniform Labelled Trees.pdf:pdf},
issn = {0895-4801},
journal = {SIAM Journal on Discrete Mathematics},
keywords = {05c05,05c80,1990,3,450-465,60c05,60j10,abbreviated title,ams,discrete math,mos,random spanning trees,random tree,random walk on graph,siam j,spanning tree,subject classification},
month = {nov},
number = {4},
pages = {450--465},
title = {{The Random Walk Construction of Uniform Spanning Trees and Uniform Labelled Trees}},
url = {http://epubs.siam.org/doi/10.1137/0403039},
volume = {3},
year = {1990}
}
@inproceedings{AnGhRe16,
abstract = {Strongly Rayleigh distributions are natural generalizations of product and determinantal probability distributions and satisfy strongest form of negative dependence properties. We show that the "natural" Monte Carlo Markov Chain (MCMC) is rapidly mixing in the support of a {\{}$\backslash$em homogeneous{\}} strongly Rayleigh distribution. As a byproduct, our proof implies Markov chains can be used to efficiently generate approximate samples of a {\$}k{\$}-determinantal point process. This answers an open question raised by Deshpande and Rademacher.},
address = {New York, USA},
archivePrefix = {arXiv},
arxivId = {1602.05242},
author = {Anari, Nima and Gharan, Shayan Oveis and Rezaei, Alireza},
booktitle = {Conference on Learning Theory (COLT)},
eprint = {1602.05242},
pages = {103--115},
publisher = {PMLR},
title = {{Monte Carlo Markov Chain Algorithms for Sampling Strongly Rayleigh Distributions and Determinantal Point Processes}},
url = {http://proceedings.mlr.press/v49/anari16},
year = {2016}
}
@article{AvGa13,
abstract = {Consider a finite weighted oriented graph. We study a probability measure on the set of spanning rooted oriented forests on the graph. We prove that the set of roots sampled from this measure is a determinantal process, characterized by a possibly non-symmetric kernel with complex eigenvalues. We then derive several results relating this measure to the Markov process associated with the starting graph, to the spectrum of its generator and to hitting times of subsets of the graph. In particular, the mean hitting time of the set of roots turns out to be independent of the starting point, conditioning or not to a given number of roots. Wilson's algorithm provides a way to sample this measure and, in absence of complex eigenvalues of the generator, we explain how to get samples with a number of roots approximating a prescribed integer. We also exploit the properties of this measure to give some probabilistic insight into the proof of an algebraic result due to Micchelli and Willoughby [13]. Further, we present two different related coalescence and fragmentation processes.},
author = {Avena, Luca and Gaudilli{\`{e}}re, Alexandre},
file = {:Users/ggautier/Documents/Mendeley Desktop/Avena, Gaudilli{\`{e}}re - 2013 - On some random forests with determinantal roots.pdf:pdf},
journal = {e-prints},
keywords = {05C81,05C85 Keywords,15A15,15A18,60J20,Finite networks,MSC 2010,Wilson's algorithm,coalescence and frag-mentation,determinantal processes,hit-ting times,local equilibria,primary,random partitions,random sets,secondary,spanning forests},
title = {{On some random forests with determinantal roots}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.740.6173{\&}rep=rep1{\&}type=pdf},
year = {2013}
}
@article{BaTu05,
abstract = {spatstat is a package for analyzing spatial point pattern data. Its functionality includes exploratory data analysis, model-fitting, and simulation. It is designed to handle realistic datasets, including inhomogeneous point patterns, spatial sampling regions of arbitrary shape, extra covariate data, and "marks" attached to the points of the point pattern. A unique feature of spatstat is its generic algorithm for fitting point process models to point pattern data. The interface to this algorithm is a function ppm that is strongly analogous to lm and glm. This paper is a general description of spatstat and an introduction for new users.},
author = {Baddeley, Adrian and Turner, Rolf},
doi = {10.18637/jss.v012.i06},
issn = {1548-7660},
journal = {Journal of Statistical Software},
month = {jan},
number = {6},
pages = {1--42},
title = {{spatstat : An R Package for Analyzing Spatial Point Patterns}},
url = {http://www.jstatsoft.org/v12/i06/},
volume = {12},
year = {2005}
}
@article{BaHa16,
abstract = {We show that repulsive random variables can yield Monte Carlo methods with faster convergence rates than the typical {\$}N{\^{}}{\{}-1/2{\}}{\$}, where {\$}N{\$} is the number of integrand evaluations. More precisely, we propose stochastic numerical quadratures involving determinantal point processes associated with multivariate orthogonal polynomials, and we obtain root mean square errors that decrease as {\$}N{\^{}}{\{}-(1+1/d)/2{\}}{\$}, where {\$}d{\$} is the dimension of the ambient space. First, we prove a central limit theorem (CLT) for the linear statistics of a class of determinantal point processes, when the reference measure is a product measure supported on a hypercube, which satisfies the Nevai-class regularity condition, a result which may be of independent interest. Next, we introduce a Monte Carlo method based on these determinantal point processes, and prove a CLT with explicit limiting variance for the quadrature error, when the reference measure satisfies a stronger regularity condition. As a corollary, by taking a specific reference measure and using a construction similar to importance sampling, we obtain a general Monte Carlo method, which applies to any measure with continuously derivable density. Loosely speaking, our method can be interpreted as a stochastic counterpart to Gaussian quadrature, which, at the price of some convergence rate, is easily generalizable to any dimension and has a more explicit error term.},
archivePrefix = {arXiv},
arxivId = {1605.00361},
author = {Bardenet, R{\'{e}}mi and Hardy, Adrien},
eprint = {1605.00361},
file = {:Users/ggautier/Documents/Mendeley Desktop/Bardenet, Hardy - 2016 - Monte Carlo with Determinantal Point Processes.pdf:pdf},
journal = {ArXiv e-prints},
title = {{Monte Carlo with Determinantal Point Processes}},
url = {http://arxiv.org/abs/1605.00361},
year = {2016}
}
@article{Bor09,
abstract = {We present a list of algebraic, combinatorial, and analytic mechanisms that give rise to determinantal point processes.},
archivePrefix = {arXiv},
arxivId = {0911.1153},
author = {Borodin, Alexei},
eprint = {0911.1153},
journal = {ArXiv e-prints},
keywords = {Mathematical Physics,Mathematics - Probability},
title = {{Determinantal point processes}},
url = {http://arxiv.org/abs/0911.1153},
year = {2009}
}
@article{BoDiFu10,
abstract = {Adding a column of numbers produces "carries" along the way. We show that random digits produce a pattern of carries with a neat probabilistic description: the carries form a one-dependent determinantal point process. This makes it easy to answer natural questions: How many carries are typical? Where are they located? We show that many further examples, from combinatorics, algebra and group theory, have essentially the same neat formulae, and that any one-dependent point process on the integers is determinantal. The examples give a gentle introduction to the emerging fields of one-dependent and determinantal point processes.},
archivePrefix = {arXiv},
arxivId = {0904.3740},
author = {Borodin, Alexei and Diaconis, Persi and Fulman, Jason},
eprint = {0904.3740},
file = {:Users/ggautier/Documents/Mendeley Desktop/Borodin, Diaconis, Fulman - 2009 - On adding a list of numbers (and other one-dependent determinantal processes).pdf:pdf},
journal = {Bulletin of the American Mathematical Society},
number = {4},
pages = {639--670},
title = {{On adding a list of numbers (and other one-dependent determinantal processes)}},
url = {http://www.ams.org/journals/bull/2010-47-04/S0273-0979-2010-01306-9/S0273-0979-2010-01306-9.pdf},
volume = {47},
year = {2010}
}
@inproceedings{BuRaWi19,
archivePrefix = {arXiv},
arxivId = {1903.03571},
author = {Burt, David and Rasmussen, Carl Edward and Wilk, Mark Van Der},
booktitle = {International Conference on Machine Learning (ICML)},
eprint = {1903.03571},
file = {:Users/ggautier/Documents/Mendeley Desktop/Burt, Rasmussen, Wilk - 2019 - Rates of Convergence for Sparse Variational Gaussian Process Regression.pdf:pdf},
month = {may},
pages = {862--871},
title = {{Rates of Convergence for Sparse Variational Gaussian Process Regression}},
url = {http://proceedings.mlr.press/v97/burt19a.html},
year = {2019}
}
@book{DaVe03,
address = {New York, USA},
author = {Daley, Daryl J. and Vere-Jones, David},
doi = {10.1007/b97277},
edition = {2},
file = {:Users/ggautier/Documents/Mendeley Desktop/Daley, Vere-Jones - 2008 - An introduction to the theory of point processes. Vol I.pdf:pdf},
isbn = {0-387-95541-0},
pages = {471},
publisher = {Springer-Verlag New York},
series = {Probability and its Applications},
title = {{An Introduction to the Theory of Point Processes. Volume I: Elementary Theory and Methods}},
url = {http://link.springer.com/10.1007/b97277},
year = {2003}
}
@article{DFL13,
abstract = {Determinantal point processes (DPP) serve as a practicable modeling for many applications of repulsive point processes. A known approach for simulation was proposed in $\backslash$cite{\{}Hough(2006){\}}, which generate the desired distribution point wise through rejection sampling. Unfortunately, the size of rejection could be very large. In this paper, we investigate the application of perfect simulation via coupling from the past (CFTP) on DPP. We give a general framework for perfect simulation on DPP model. It is shown that the limiting sequence of the time-to-coalescence of the coupling is bounded by {\$}K|\backslashLambda|\backslashlog K|\backslashLambda|{\$}. An application is given to the stationary models in DPP.},
archivePrefix = {arXiv},
arxivId = {1311.1027},
author = {Decreusefond, Laurent and Flint, Ian and Low, Kah Choon},
eprint = {1311.1027},
journal = {ArXiv e-prints},
keywords = {Mathematics - Probability,Mathematics - Statistics Theory},
title = {{Perfect Simulation of Determinantal Point Processes}},
url = {http://arxiv.org/abs/1311.1027},
year = {2013}
}
@inproceedings{DeCaVa19,
abstract = {We study the complexity of sampling from a distribution over all index subsets of the set {\{}1, ..., n{\}} with the probability of a subset S proportional to the determinant of the submatrix L S of some n × n p.s.d. matrix L, where L S corresponds to the entries of L indexed by S. Known as a de-terminantal point process (DPP), this distribution is widely used in machine learning to induce diversity in subset selection. In practice, we often wish to sample multiple subsets S with small expected size k = E[|S|] n from a very large matrix L, so it is important to minimize the pre-processing cost of the procedure (performed once) as well as the sampling cost (performed repeatedly). To that end, we propose a new algorithm which, given access to L, samples exactly from a DPP while satisfying the following two properties: (1) its preprocessing cost is n {\textperiodcentered} poly(k) (sublinear in the size of L) and (2) its sampling cost is poly(k) (independent of the size of L). Prior to this work, state-of-the-art exact samplers required O(n 3) preprocessing time and sampling time linear in n or dependent on L's spectrum.},
archivePrefix = {arXiv},
arxivId = {1905.13476},
author = {Derezi{\'{n}}ski, Michal and Calandriello, Daniele and Valko, Michal},
booktitle = {Workshop on Negative Dependence in Machine Learning, International Conference on Machine Learning (ICML)},
eprint = {1905.13476},
file = {:Users/ggautier/Documents/Mendeley Desktop/Derez{\'{i}}, Calandriello, Valko - 2019 - Exact sampling of determinantal point processes with sublinear time preprocessing.pdf:pdf},
title = {{Exact sampling of determinantal point processes with sublinear time preprocessing}},
url = {https://negative-dependence-in-ml-workshop.lids.mit.edu/wp-content/uploads/sites/29/2019/06/icml.pdf},
year = {2019}
}
@article{DuEd15,
abstract = {The four major asymptotic level density laws of random matrix theory may all be showcased though their Jacobi parameter representation as having a bordered Toeplitz form. We compare and contrast these laws, completing and exploring their representations in one place. Inspired by the bordered Toeplitz form, we propose an algorithm for the finite moment problem by proposing a solution whose density has a bordered Toeplitz form.},
archivePrefix = {arXiv},
arxivId = {1502.04931},
author = {Dubbs, Alexander and Edelman, Alan},
doi = {10.1016/j.laa.2014.11.006},
eprint = {1502.04931},
issn = {00243795},
journal = {Linear Algebra and its Applications},
keywords = {Finite moment problem,Infinite random matrix theory,Jacobi parameters,Toeplitz matrix},
pages = {188--201},
title = {{Infinite Random Matrix Theory, Tridiagonal Bordered Toeplitz Matrices, and the Moment Problem}},
volume = {467},
year = {2015}
}
@article{DuEd02,
abstract = {This paper constructs tridiagonal random matrix models for general ({\$}\backslashbeta{\textgreater}0{\$}) {\$}\backslashbeta{\$}-Hermite (Gaussian) and {\$}\backslashbeta{\$}-Laguerre (Wishart) ensembles. These generalize the well-known Gaussian and Wishart models for {\$}\backslashbeta = 1,2,4{\$}. Furthermore, in the cases of the {\$}\backslashbeta{\$}-Laguerre ensembles, we eliminate the exponent quantization present in the previously known models. We further discuss applications for the new matrix models, and present some open problems.},
archivePrefix = {arXiv},
arxivId = {math-ph/0206043},
author = {Dumitriu, Ioana and Edelman, Alan},
doi = {10.1063/1.1507823},
eprint = {0206043},
file = {:Users/ggautier/Documents/Mendeley Desktop/JMathPhys{\_}43{\_}5830.pdf:pdf},
isbn = {doi:10.1063/1.1507823},
issn = {0022-2488},
journal = {Journal of Mathematical Physics},
number = {11},
pages = {5830--5847},
primaryClass = {math-ph},
title = {{Matrix Models for Beta Ensembles}},
url = {https://sites.math.washington.edu/{~}dumitriu/JMathPhys{\_}43{\_}5830.pdf},
volume = {43},
year = {2002}
}
@inproceedings{DuBa18,
abstract = {We propose a new class of determinantal point processes (DPPs) which can be manipulated for inference and parameter learning in potentially sublinear time in the number of items. This class, based on a specific low-rank factorization of the marginal kernel, is particularly suited to a subclass of continuous DPPs and DPPs defined on exponentially many items. We apply this new class to modelling text documents as sampling a DPP of sentences, and propose a conditional maximum likelihood formulation to model topic proportions, which is made possible with no approximation for our class of DPPs. We present an application to document summarization with a DPP on {\$}2{\^{}}{\{}500{\}}{\$} items.},
address = {Lanzarote, Spain},
archivePrefix = {arXiv},
arxivId = {1610.05925},
author = {Dupuy, Christophe and Bach, Francis},
booktitle = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
eprint = {1610.05925},
pages = {244--257},
publisher = {PMLR},
title = {{Learning Determinantal Point Processes in Sublinear Time}},
url = {http://proceedings.mlr.press/v84/dupuy18a},
volume = {84},
year = {2018}
}
@article{GBDK19,
abstract = {Determinantal point processes (DPPs) have attracted substantial attention as an elegant probabilistic model that captures the balance between quality and diversity within sets. DPPs are conventionally parameterized by a positive semi-definite kernel matrix, and this symmetric kernel encodes only repulsive interactions between items. These so-called symmetric DPPs have significant expressive power, and have been successfully applied to a variety of machine learning tasks, including recommendation systems, information retrieval, and automatic summarization, among many others. Efficient algorithms for learning symmetric DPPs and sampling from these models have been reasonably well studied. However, relatively little attention has been given to nonsymmetric DPPs, which relax the symmetric constraint on the kernel. Nonsymmetric DPPs allow for both repulsive and attractive item interactions, which can significantly improve modeling power, resulting in a model that may better fit for some applications. We present a method that enables a tractable algorithm, based on maximum likelihood estimation, for learning nonsymmetric DPPs from data composed of observed subsets. Our method imposes a particular decomposition of the nonsymmetric kernel that enables such tractable learning algorithms, which we analyze both theoretically and experimentally. We evaluate our model on synthetic and real-world datasets, demonstrating improved predictive performance compared to symmetric DPPs, which have previously shown strong performance on modeling tasks associated with these datasets.},
archivePrefix = {arXiv},
arxivId = {1905.12962},
author = {Gartrell, Mike and Brunel, Victor-Emmanuel and Dohmatob, Elvis and Krichene, Syrine},
eprint = {1905.12962},
file = {::},
journal = {ArXiv e-prints},
month = {may},
title = {{Learning Nonsymmetric Determinantal Point Processes}},
url = {http://arxiv.org/abs/1905.12962},
year = {2019}
}
@inproceedings{GaPaKo16,
abstract = {Determinantal point processes (DPPs) have garnered attention as an elegant probabilistic model of set diversity. They are useful for a number of subset selection tasks, including product recommendation. DPPs are parametrized by a positive semi-definite kernel matrix. In this work we present a new method for learning the DPP kernel from observed data using a low-rank factorization of this kernel. We show that this low-rank factorization enables a learning algorithm that is nearly an order of magnitude faster than previous approaches, while also providing for a method for computing product recommendation predictions that is far faster (up to 20x faster or more for large item catalogs) than previous techniques that involve a full-rank DPP kernel. Furthermore, we show that our method provides equivalent or sometimes better predictive performance than prior full-rank DPP approaches, and better performance than several other competing recommendation methods in many cases. We conduct an extensive experimental evaluation using several real-world datasets in the domain of product recommendation to demonstrate the utility of our method, along with its limitations.},
annote = {From Duplicate 2 (Low-Rank Factorization of Determinantal Point Processes for Recommendation - Gartrell, Mike; Paquet, Ulrich; Koenigstein, Noam)

NULL},
archivePrefix = {arXiv},
arxivId = {1602.05436},
author = {Gartrell, Mike and Paquet, Ulrich and Koenigstein, Noam},
booktitle = {AAAI Conference on Artificial Intelligence},
eprint = {1602.05436},
file = {:Users/ggautier/Documents/Mendeley Desktop/a9ae21aebe1a80de7974af509d241f3055f8ea46.pdf:pdf},
keywords = {Machine Learning Methods},
pages = {1912--1918},
title = {{Low-Rank Factorization of Determinantal Point Processes for Recommendation}},
url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14657/14354},
year = {2016}
}
@inproceedings{GaBaVa19,
abstract = {This paper focuses on Monte Carlo integration with determinantal point processes (DPPs) which enforce negative dependence between quadrature nodes. We survey the properties of two unbiased Monte Carlo estimators of the integral of interest: a direct one proposed by Bardenet {\&} Hardy (2016) and a less obvious 60-year-old estimator by Ermakov {\&} Zolotukhin (1960) that actually also relies on DPPs. We provide an efficient implementation to sample exactly a particular multidimen-sional DPP called multivariate Jacobi ensemble. This let us investigate the behavior of both estima-tors on toy problems in yet unexplored regimes.},
author = {Gautier, Guillaume and Bardenet, R{\'{e}}mi and Valko, Michal},
booktitle = {Workshop on Negative Dependence in Machine Learning, International Conference in Machine Learning (ICML)},
file = {::},
title = {{On two ways to use determinantal point processes for Monte Carlo integration}},
url = {https://negative-dependence-in-ml-workshop.lids.mit.edu/wp-content/uploads/sites/29/2019/06/icml{\_}camera{\_}ready.pdf},
year = {2019}
}
@article{GaBaVa17,
abstract = {Determinantal point processes (DPPs) are distributions over sets of items that model diversity using kernels. Their applications in machine learning include summary extraction and recommendation systems. Yet, the cost of sampling from a DPP is prohibitive in large-scale applications, which has triggered an effort towards efficient approximate samplers. We build a novel MCMC sampler that combines ideas from combinatorial geometry, linear programming, and Monte Carlo methods to sample from DPPs with a fixed sample cardinality, also called projection DPPs. Our sampler leverages the ability of the hit-and-run MCMC kernel to efficiently move across convex bodies. Previous theoretical results yield a fast mixing time of our chain when targeting a distribution that is close to a projection DPP, but not a DPP in general. Our empirical results demonstrate that this extends to sampling projection DPPs, i.e., our sampler is more sample-efficient than previous approaches which in turn translates to faster convergence when dealing with costly-to-evaluate functions, such as summary extraction in our experiments.},
address = {Sydney, Australia},
archivePrefix = {arXiv},
arxivId = {1705.10498},
author = {Gautier, Guillaume and Bardenet, R{\'{e}}mi and Valko, Michal},
eprint = {1705.10498},
isbn = {9781510855144},
journal = {International Conference on Machine Learning (ICML)},
month = {may},
pages = {1223--1232},
publisher = {PMLR},
title = {{Zonotope hit-and-run for efficient sampling from projection DPPs}},
url = {http://proceedings.mlr.press/v70/gautier17a},
year = {2017}
}
@article{GPBV18,
abstract = {Determinantal point processes (DPPs) are specific probability distributions over clouds of points that are used as models and computational tools across physics, probability, statistics, and more recently machine learning. Sampling from DPPs is a challenge and therefore we present DPPy, a Python toolbox that gathers known exact and approximate sampling algorithms for both finite and continuous DPPs. The project is hosted on GitHub and equipped with an extensive documentation.},
archivePrefix = {arXiv},
arxivId = {1809.07258},
author = {Gautier, Guillaume and Polito, Guillermo and Bardenet, R{\'{e}}mi and Valko, Michal},
eprint = {1809.07258},
file = {::},
journal = {ArXiv e-prints},
month = {sep},
title = {{DPPy: Sampling DPPs with Python}},
url = {http://arxiv.org/abs/1809.07258},
year = {2018}
}
@article{Gau09,
abstract = {Bernstein's inequality for Jacobi polynomials P ($\alpha$,$\beta$) n , established in 1987 by P. Baratella for the region R 1/2 = {\{}|$\alpha$| ≤ 1/2, |$\beta$| ≤ 1/2{\}}, and subsequently supplied with an improved constant by Y. Chow, L. Gatteschi, and R. Wong, is analyzed here analytically and, above all, computationally with regard to validity and sharpness, not only in the original region R 1/2 , but also in larger regions R s = {\{}−1/2 ≤ $\alpha$ ≤ s, −1/2 ≤ $\beta$ ≤ s{\}}, s {\textgreater} 1/2. Computation suggests that the inequality holds with new, somewhat larger, constants in any region R s. Best constants are provided for s = 1 : .5 : 4 and s = 5 : 1 : 10. Our work also sheds new light on the so-called Erd{\'{e}}lyi-Magnus-Nevai conjecture for orthonormal Jacobi polynomials, adding further support for its validity and suggesting .66198126. .. as the best constant implied in the conjecture.},
author = {Gautschi, Walter},
file = {:Users/ggautier/Documents/Mendeley Desktop/Gautschi - 2009 - How sharp is Bernstein's Inequality for Jacobi polynomials.pdf:pdf},
journal = {Electronic Transactions on Numerical Analysis},
pages = {1--8},
title = {{How sharp is Bernstein's Inequality for Jacobi polynomials?}},
url = {http://emis.ams.org/journals/ETNA/vol.36.2009-2010/pp1-8.dir/pp1-8.pdf},
volume = {36},
year = {2009}
}
@phdthesis{Gil14,
author = {Gillenwater, Jennifer},
booktitle = {Publicly Accessible Penn Dissertations. 1285.},
school = {University of Pennsylvania},
title = {{Approximate inference for determinantal point processes}},
url = {https://repository.upenn.edu/edissertations/1285},
year = {2014}
}
@inproceedings{HKPV06,
abstract = {We give a probabilistic introduction to determinantal and permanental point processes. Determinantal processes arise in physics (fermions, eigenvalues of random matrices) and in combinatorics (nonintersecting paths, random spanning trees). They have the striking property that the number of points in a region {\$}D{\$} is a sum of independent Bernoulli random variables, with parameters which are eigenvalues of the relevant operator on {\$}L{\^{}}2(D){\$}. Moreover, any determinantal process can be represented as a mixture of determinantal projection processes. We give a simple explanation for these known facts, and establish analogous representations for permanental processes, with geometric variables replacing the Bernoulli variables. These representations lead to simple proofs of existence criteria and central limit theorems, and unify known results on the distribution of absolute values in certain processes with radially symmetric distributions.},
archivePrefix = {arXiv},
arxivId = {math/0503110},
author = {Hough, J. Ben and Krishnapur, Manjunath and Peres, Yuval and Vir{\'{a}}g, B{\'{a}}lint},
booktitle = {Probability Surveys},
doi = {10.1214/154957806000000078},
eprint = {0503110},
file = {:Users/ggautier/Documents/Mendeley Desktop/Hough et al. - 2006 - Determinantal Processes and Independence.pdf:pdf},
issn = {1549-5787},
pages = {206--229},
primaryClass = {math},
publisher = {The Institute of Mathematical Statistics and the Bernoulli Society},
title = {{Determinantal Processes and Independence}},
url = {http://arxiv.org/abs/math/0503110},
volume = {3},
year = {2006}
}
@article{Joh06,
abstract = {We survey recent results on determinantal processes, random growth, random tilings and their relation to random matrix theory.},
archivePrefix = {arXiv},
arxivId = {math-ph/0510038},
author = {Johansson, Kurt},
doi = {10.1016/S0924-8099(06)80038-7},
eprint = {0510038},
file = {:Users/ggautier/Documents/Mendeley Desktop/Johansson - 2006 - Course 1 Random matrices and determinantal processes(2).pdf:pdf},
issn = {09248099},
journal = {Les Houches Summer School Proceedings},
number = {C},
pages = {1--56},
primaryClass = {math-ph},
title = {{Random matrices and determinantal processes}},
volume = {83},
year = {2006}
}
@article{Kam18,
archivePrefix = {arXiv},
arxivId = {1805.05253},
author = {Kammoun, Mohamed Slim},
doi = {10.1214/18-EJP244},
eprint = {1805.05253},
journal = {Electronic Journal of Probability},
number = {0},
publisher = {The Institute of Mathematical Statistics and the Bernoulli Society},
title = {{Monotonous subsequences and the descent process of invariant random permutations}},
url = {https://projecteuclid.org/euclid.ejp/1543287754},
volume = {23},
year = {2018}
}
@inproceedings{KaDeKo16,
abstract = {Gaussian Process bandit optimization has emerged as a powerful tool for optimizing noisy black box functions. One example in machine learning is hyper-parameter optimization where each evaluation of the target function requires training a model which may involve days or even weeks of computation. Most methods for this so-called "Bayesian optimization" only allow sequential exploration of the parameter space. However, it is often desirable to propose batches or sets of parameter values to explore simultaneously, especially when there are large parallel processing facilities at our disposal. Batch methods require modeling the interaction between the different evaluations in the batch, which can be expensive in complex scenarios. In this paper, we propose a new approach for parallelizing Bayesian optimization by modeling the diversity of a batch via Determinantal point processes (DPPs) whose kernels are learned automatically. This allows us to generalize a previous result as well as prove better regret bounds based on DPP sampling. Our experiments on a variety of synthetic and real-world robotics and hyper-parameter optimization tasks indicate that our DPP-based methods, especially those based on DPP sampling, outperform state-of-the-art methods.},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1611.04088},
author = {Kathuria, Tarun and Deshpande, Amit and Kohli, Pushmeet},
booktitle = {Neural Information Processing Systems (NIPS)},
eprint = {1611.04088},
pages = {4206--4214},
title = {{Batched Gaussian Process Bandit Optimization via Determinantal Point Processes}},
url = {http://papers.nips.cc/paper/6452-batched-gaussian-process-bandit-optimization-via-determinantal-point-processes},
year = {2016}
}
@article{Ker96,
author = {Kerov, Sergei},
journal = {Proceedings of St.Petersburg Mathematical Society},
title = {{A Differential Model Of Growth Of Young Diagrams}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.30.7744},
volume = {4},
year = {1996}
}
@article{KiNe04,
abstract = {We describe an ensemble of (sparse) random matrices whose eigenvalues follow the Gibbs distribution for n particles of the Coulomb gas on the unit circle at inverse temperature beta. Our approach combines elements from the theory of orthogonal polynomials on the unit circle with ideas from recent work of Dumitriu and Edelman. In particular, we resolve a question left open by them: find a tri-diagonal model for the Jacobi ensemble.},
archivePrefix = {arXiv},
arxivId = {math/0410034},
author = {Killip, Rowan and Nenciu, Irina},
doi = {10.1155/S1073792804141597},
eprint = {0410034},
issn = {1073-7928},
journal = {International Mathematics Research Notices},
number = {50},
pages = {2665},
primaryClass = {math},
title = {{Matrix models for circular ensembles}},
url = {https://academic.oup.com/imrn/article-lookup/doi/10.1155/S1073792804141597},
volume = {2004},
year = {2004}
}
@article{Kon05,
abstract = {We survey a number of models from physics, statistical mechanics, probability theory and combinatorics, which are each described in terms of an orthogonal polynomial ensemble. The most prominent example is apparently the Hermite ensemble, the eigenvalue distribution of the Gaussian Unitary Ensemble (GUE), and other well-known ensembles known in random matrix theory like the Laguerre ensemble for the spectrum of Wishart matrices. In recent years, a number of further interesting models were found to lead to orthogonal polynomial ensembles, among which the corner growth model, directed last passage percolation, the PNG droplet, non-colliding random processes, the length of the longest increasing subsequence of a random permutation, and others. Much attention has been paid to universal classes of asymptotic behaviors of these models in the limit of large particle numbers, in particular the spacings between the particles and the fluctuation behavior of the largest particle. Computer simulations suggest that the connections go even farther and also comprise the zeros of the Riemann zeta function. The existing proofs require a substantial technical machinery and heavy tools from various parts of mathematics, in particular complex analysis, combinatorics and variational analysis. Particularly in the last decade, a number of fine results have been achieved, but it is obvious that a comprehensive and thorough understanding of the matter is still lacking. Hence, it seems an appropriate time to provide a surveying text on this research area.},
archivePrefix = {arXiv},
arxivId = {math/0403090},
author = {K{\"{o}}nig, Wolfgang},
doi = {10.1214/154957805100000177},
eprint = {0403090},
issn = {1549-5787},
journal = {Probab. Surveys},
keywords = {Kon05},
pages = {385--447},
primaryClass = {math},
publisher = {The Institute of Mathematical Statistics and the Bernoulli Society},
title = {{Orthogonal polynomial ensembles in probability theory}},
url = {http://arxiv.org/abs/math/0403090},
volume = {2},
year = {2004}
}
@article{KuTa12,
abstract = {Determinantal point processes (DPPs) are elegant probabilistic models of repulsion that arise in quantum physics and random matrix theory. In contrast to traditional structured models like Markov random fields, which become intractable and hard to approximate in the presence of negative correlations, DPPs offer efficient and exact algorithms for sampling, marginalization, conditioning, and other inference tasks. We provide a gentle introduction to DPPs, focusing on the intuitions, algorithms, and extensions that are most relevant to the machine learning community, and show how DPPs can be applied to real-world applications like finding diverse sets of high-quality search results, building informative summaries by selecting diverse sentences from documents, modeling non-overlapping human poses in images or video, and automatically building timelines of important news stories.},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1207.6083},
author = {Kulesza, Alex and Taskar, Ben},
doi = {10.1561/2200000044},
eprint = {1207.6083},
file = {:Users/ggautier/Documents/Mendeley Desktop/Kulesza - 2012 - Determinantal Point Processes for Machine Learning.pdf:pdf},
issn = {1935-8237},
journal = {Foundations and Trends in Machine Learning},
number = {2-3},
pages = {123--286},
title = {{Determinantal Point Processes for Machine Learning}},
url = {http://arxiv.org/abs/1207.6083},
volume = {5},
year = {2012}
}
@article{LaGaDe18,
abstract = {Determinantal point processes (DPPs) enable the modelling of repulsion: they provide diverse sets of points. This repulsion is encoded in a kernel K that we can see as a matrix storing the similarity between points. The usual algorithm to sample DPPs is exact but it uses the spectral decomposition of K, a computation that becomes costly when dealing with a high number of points. Here, we present an alternative exact algorithm that avoids the eigenvalues and the eigenvectors computation and that is, for some applications, faster than the original algorithm.},
archivePrefix = {arXiv},
arxivId = {1802.08429},
author = {Launay, Claire and Galerne, Bruno and Desolneux, Agn{\`{e}}s},
eprint = {1802.08429},
journal = {ArXiv e-prints},
keywords = {Statistics - Machine Learning},
month = {feb},
title = {{Exact Sampling of Determinantal Point Processes without Eigendecomposition}},
url = {http://arxiv.org/abs/1802.08429},
year = {2018}
}
@article{LaMoRu15,
abstract = {Statistical models and methods for determinantal point processes (DPPs) seem largely unexplored. We demonstrate that DPPs provide useful models for the description of spatial point pattern datasets where nearby points repel each other. Such data are usually modelled by Gibbs point processes, where the likelihood and moment expressions are intractable and simulations are time consuming. We exploit the appealing probabilistic properties of DPPs to develop parametric models, where the likelihood and moment expressions can be easily evaluated and realizations can be quickly simulated. We discuss how statistical inference is conducted using the likelihood or moment properties of DPP models, and we provide freely available software for simulation and statistical inference.},
archivePrefix = {arXiv},
arxivId = {1205.4818},
author = {Lavancier, Fr{\'{e}}d{\'{e}}ric and M{\o}ller, Jesper and Rubak, Ege},
doi = {10.1111/rssb.12096},
eprint = {1205.4818},
file = {:Users/ggautier/Documents/Mendeley Desktop/Lavancier, M{\o}ller, Rubak - 2015 - Determinantal point process models and statistical inference.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Maximum-likelihood-based inference,Point process density,Product densities,Repulsiveness,Simulation,Spectral approach},
month = {may},
number = {4},
pages = {853--877},
title = {{Determinantal point process models and statistical inference : Extended version}},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12096},
volume = {77},
year = {2012}
}
@inproceedings{LiJeSr16c,
abstract = {We study probability measures induced by set functions with constraints. Such measures arise in a variety of real-world settings, where prior knowledge, resource limitations, or other pragmatic considerations impose constraints. We consider the task of rapidly sampling from such constrained measures, and develop fast Markov chain samplers for them. Our first main result is for MCMC sampling from Strongly Rayleigh (SR) measures, for which we present sharp polynomial bounds on the mixing time. As a corollary, this result yields a fast mixing sampler for Determinantal Point Processes (DPPs), yielding (to our knowledge) the first provably fast MCMC sampler for DPPs since their inception over four decades ago. Beyond SR measures, we develop MCMC samplers for probabilistic models with hard constraints and identify sufficient conditions under which their chains mix rapidly. We illustrate our claims by empirically verifying the dependence of mixing times on the key factors governing our theoretical bounds.},
address = {Barcelona, Spain},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1608.01008},
author = {Li, Chengtao and Jegelka, Stefanie and Sra, Suvrit},
booktitle = {Neural Information Processing Systems (NIPS)},
eprint = {1608.01008},
file = {:Users/ggautier/Documents/Mendeley Desktop/Li, Jegelka - 2016 - Fast Mixing Markov Chains for Strongly Rayleigh Measures , DPPs , and Constrained Sampling.pdf:pdf},
issn = {10495258},
pages = {4188--4196},
title = {{Fast Mixing Markov Chains for Strongly Rayleigh Measures, DPPs, and Constrained Sampling}},
url = {https://papers.nips.cc/paper/6182-fast-mixing-markov-chains-for-strongly-rayleigh-measures-dpps-and-constrained-sampling},
year = {2016}
}
@article{LiJeSr16d,
abstract = {In this note we consider sampling from (non-homogeneous) strongly Rayleigh probability measures. As an important corollary, we obtain a fast mixing Markov Chain sampler for Determinantal Point Processes.},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1607.03559},
author = {Li, Chengtao and Jegelka, Stefanie and Sra, Suvrit},
eprint = {1607.03559},
file = {:Users/ggautier/Documents/Mendeley Desktop/Li, Jegelka, Sra - 2016 - Fast Sampling for Strongly Rayleigh Measures with Application to Determinantal Point Processes.pdf:pdf},
journal = {ArXiv e-prints},
title = {{Fast Sampling for Strongly Rayleigh Measures with Application to Determinantal Point Processes}},
url = {http://arxiv.org/abs/1607.03559},
year = {2016}
}
@inproceedings{LiJeSr16b,
abstract = {The Nystr{\"{o}}m method has long been popular for scaling up kernel methods. Its theoretical guarantees and empirical performance rely critically on the quality of the landmarks selected. We study landmark selection for Nystr{\"{o}}m using Determinantal Point Processes (DPPs), discrete probability models that allow tractable generation of diverse samples. We prove that landmarks selected via DPPs guarantee bounds on approximation errors; subsequently, we analyze implications for kernel ridge regression. Contrary to prior reservations due to cubic complexity of DPPsampling, we show that (under certain conditions) Markov chain DPP sampling requires only linear time in the size of the data. We present several empirical results that support our theoretical analysis, and demonstrate the superior performance of DPP-based landmark selection compared with existing approaches.},
address = {New York, USA},
archivePrefix = {arXiv},
arxivId = {1603.06052},
author = {Li, Chengtao and Jegelka, Stefanie and Sra, Suvrit},
booktitle = {International Conference on Machine Learning (ICML)},
eprint = {1603.06052},
file = {:Users/ggautier/Documents/Mendeley Desktop/Li, Jegelka, Sra - Unknown - Fast DPP Sampling for Nystr{\"{o}}m with Application to Kernel Methods.pdf:pdf},
isbn = {9781510829008},
pages = {2061--2070},
title = {{Fast DPP Sampling for Nystr{\"{o}}m with Application to Kernel Methods}},
url = {http://proceedings.mlr.press/v48/lih16},
year = {2016}
}
@inproceedings{LiJeSr16a,
abstract = {Determinantal Point Processes (DPPs) are elegant probabilistic models of repulsion and diversity over discrete sets of items. But their applicability to large sets is hindered by expensive cubic-complexity matrix operations for basic tasks such as sampling. In light of this, we propose a new method for approximate sampling from discrete {\$}k{\$}-DPPs. Our method takes advantage of the diversity property of subsets sampled from a DPP, and proceeds in two stages: first it constructs coresets for the ground set of items; thereafter, it efficiently samples subsets based on the constructed coresets. As opposed to previous approaches, our algorithm aims to minimize the total variation distance to the original distribution. Experiments on both synthetic and real datasets indicate that our sampling algorithm works efficiently on large data sets, and yields more accurate samples than previous approaches.},
address = {Cadiz, Spain},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1509.01618},
author = {Li, Chengtao and Jegelka, Stefanie and Sra, Suvrit},
booktitle = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
eprint = {1509.01618},
file = {:Users/ggautier/Documents/Mendeley Desktop/Li, Jegelka, Sra - Unknown - Efficient Sampling for k-Determinantal Point Processes(2).pdf:pdf},
pages = {1328--1337},
title = {{Efficient Sampling for k-Determinantal Point Processes}},
url = {http://proceedings.mlr.press/v51/li16f},
year = {2016}
}
@article{Lyo02,
abstract = {Determinantal point processes have arisen in diverse settings in recent years and have been investigated intensively. We study basic combinatorial and probabilistic aspects in the discrete case. Our main results concern relationships with matroids, stochastic domination, negative association, completeness for infinite matroids, tail triviality, and a method for extension of results from orthogonal projections to positive contractions. We also present several new avenues for further investigation, involving Hilbert spaces, combinatorics, homology, and group representations, among other areas.},
annote = {From Duplicate 2 (Determinantal probability measures - Lyons, Russell)

NULL},
archivePrefix = {arXiv},
arxivId = {math/0204325},
author = {Lyons, Russell},
doi = {10.1007/s10240-003-0016-0},
eprint = {0204325},
file = {:Users/ggautier/Documents/Mendeley Desktop/Lyons - 2002 - Determinantal probability measures.pdf:pdf},
issn = {0073-8301},
journal = {Publications math{\'{e}}matiques de l'IH{\'{E}}S},
month = {apr},
number = {1},
pages = {167--212},
primaryClass = {math},
publisher = {Springer-Verlag},
title = {{Determinantal probability measures}},
url = {http://link.springer.com/10.1007/s10240-003-0016-0},
volume = {98},
year = {2002}
}
@article{Mac75,
abstract = {The structure of the probability space associated with a general point process, when regarded as a counting process, is reviewed using the coincidence formalism. The rest of the paper is devoted to the class of regular point processes for which all coincidence probabilities admit densities. It is shown that their distribution is completely specified by the system of coincidence densities. The specification formalism is stressed for ‘completely' regular point processes. A construction theorem gives a characterization of the system of coincidence densities of such a process. It permits the study of most models of point processes. New results on the photon process, a particular type of conditioned Poisson process, are derived. New examples are exhibited, including the Gauss-Poisson process and the ‘fermion' process that is suitable whenever the points are repulsive.},
author = {Macchi, Odile},
doi = {10.2307/1425855},
isbn = {978-3-540-78571-2},
issn = {0001-8678},
journal = {Advances in Applied Probability},
number = {01},
pages = {83--122},
title = {{The coincidence approach to stochastic point processes}},
url = {https://www.cambridge.org/core/product/identifier/S0001867800040313/type/journal{\_}article},
volume = {7},
year = {1975}
}
@article{MaCoAm19,
abstract = {In computer experiments setting, space-filling designs are used to produce inputs, viewed as point patterns. A first important property of the design is that the point pattern covers regularly the input space. A second property is the conservation of this regular covering if the point pattern is projected onto a lower dimensional space. According to the first requirement, it seems then natural to consider classes of spatial point process which generate repulsive patterns. The class of determinantal point processes (DPPs) is considered in this paper. In particular, we address the question: Can we construct a DPP such that any projection on a lower-dimensional space remains a DPP, or at least remains repulsive? By assuming a particular form for the kernel defining the DPP, we prove rigorously that the answer is positive. We propose several examples of models, and in particular stationary models, achieving this property. These models defined on a compact set of R d are shown to be efficient for Monte-Carlo integration problems; we show that the same initial spatial design, defined in R d , can be used to efficiently estimate integrals of R $\omega$-valued for any $\omega$ = 1,. .. , d.},
archivePrefix = {arXiv},
arxivId = {1901.02099v3},
author = {Mazoyer, Adrien and Coeurjolly, Jean-Fran{\c{c}}ois and Amblard, Pierre-Olivier},
eprint = {1901.02099v3},
file = {:Users/ggautier/Documents/Mendeley Desktop/Mazoyer, Coeurjolly, Amblard - 2019 - Projections of determinantal point processes.pdf:pdf},
journal = {ArXiv e-prints},
title = {{Projections of determinantal point processes}},
url = {https://arxiv.org/pdf/1901.02099.pdf},
year = {2019}
}
@article{Mez06,
abstract = {We discuss how to generate random unitary matrices from the classical compact groups U(N), O(N) and USp(N) with probability distributions given by the respective invariant measures. The algorithm is straightforward to implement using standard linear algebra packages. This approach extends to the Dyson circular ensembles too. This article is based on a lecture given by the author at the summer school on Number Theory and Random Matrix Theory held at the University of Rochester in June 2006. The exposition is addressed to a general mathematical audience.},
archivePrefix = {arXiv},
arxivId = {math-ph/0609050},
author = {Mezzadri, Francesco},
eprint = {0609050},
journal = {Notices of the American Mathematical Society},
keywords = {1502,15A52,65F25,Mathematical Physics,Mathematics - Numerical Analysis},
month = {sep},
pages = {592--604},
primaryClass = {math-ph},
title = {{How to generate random matrices from the classical compact groups}},
url = {http://arxiv.org/abs/math-ph/0609050},
volume = {54},
year = {2006}
}
@book{MoWa04,
abstract = {Spatial point processes play a fundamental role in spatial statistics and today they are an active area of research with many new applications. Although other published works address different aspects of spatial point processes, most of the classical literature deals only with nonparametric methods, and a thorough treatment of the theory and applications of simulation-based inference is difficult to find. Written by researchers at the top of the field, this book collects and unifies recent theoretical advances and examples of applications. The authors examine Markov chain Monte Carlo algorithms and explore one of the most important recent developments in MCMC: perfect simulation procedures.},
author = {M{\o}ller, Jesper. and Waagepetersen, Rasmus Plenge.},
doi = {10.1201/9780203496930},
file = {:Users/ggautier/Documents/Mendeley Desktop/M{\o}ller, Waagepetersen - 2004 - Statistical inference and simulation for spatial point processes.pdf:pdf},
isbn = {1584882654},
issn = {0277-6715},
keywords = {point processes,spatial analysis (Statistics)},
pages = {320},
publisher = {Chapman {\&} Hall/CRC},
title = {{Statistical inference and simulation for spatial point processes}},
url = {https://www.crcpress.com/Statistical-Inference-and-Simulation-for-Spatial-Point-Processes/Moller-Waagepetersen/p/book/9781584882657},
volume = {23},
year = {2004}
}
@book{PaBe11,
abstract = {This classic text, first published in 1972, is designed for graduate physics courses in statistical mechanics. The second edition, published in 1996, incorporated three comprehensive chapters on phase transitions and critical phenomena. This third edition includes new sections on Bose-Einstein condensation and degenerate Fermi behavior of ultracold atomic gases, and two new chapters on computer simulation methods and the thermodynamics of the early universe. We have also added new sections on chemical and phase equilibrium, and expanded our discussions of correlations and scattering, quantized fields, finite-size effects and the fluctuation-dissipation theorem. We hope this new edition will continue to provide new generations of students with a solid training in the methods of statistical physics.-Bose-Einstein condensation in atomic gases -Thermodynamics of the early universe -Computer simulations: Monte Carlo and molecular dynamics -Correlation functions and scattering -Fluctuation-dissipation theorem and the dynamical structure factor -Chemical equilibrium -Exact solution of the two-dimensional Ising model for finite systems -Degenerate atomic Fermi gases -Exact solutions of one-dimensional fluid models -Interactions in ultracold Bose and Fermi gases -Brownian motion of anisotropic particles and harmonic oscillators},
annote = {From Duplicate 2 (Statistical Mechanics - Pathria, R K; Beale, Paul D.)

NULL},
author = {Pathria, Raj K. and Beale, Paul D.},
booktitle = {Statistical Mechanics},
doi = {10.1016/B978-0-12-382188-1.00020-7},
isbn = {0123821894},
issn = {0024094X},
pages = {744},
pmid = {23138097},
publisher = {Academic Press},
title = {{Statistical Mechanics}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780123821881000207},
year = {2011}
}
@article{Pou19,
abstract = {Determinantal Point Processes (DPPs) were introduced by Macchi as a model for repulsive (fermionic) particle distributions. But their recent popularization is largely due to their usefulness for encouraging diversity in the final stage of a recommender system. The standard sampling scheme for finite DPPs is a spectral decomposition followed by an equivalent of a randomly diagonally-pivoted Cholesky factorization of an orthogonal projection, which is only applicable to Hermitian kernels and has an expensive setup cost. Researchers have begun to connect DPP sampling to {\$}LDL{\^{}}H{\$} factorizations as a means of avoiding the initial spectral decomposition, but existing approaches have only outperformed the spectral decomposition approach in special circumstances, where the number of kept modes is a small percentage of the ground set size. This article proves that trivial modifications of {\$}LU{\$} and {\$}LDL{\^{}}H{\$} factorizations yield efficient direct sampling schemes for non-Hermitian and Hermitian DPP kernels, respectively. Further, it is experimentally shown that even dynamically-scheduled, shared-memory parallelizations of high-performance dense and sparse-direct factorizations can be trivially modified to yield DPP sampling schemes with essentially identical performance. The software developed as part of this research, Catamari, https://hodgestar.com/catamari, is released under the Mozilla Public License v2.0. It contains header-only, C++14 plus OpenMP 4.0 implementations of dense and sparse-direct, Hermitian and non-Hermitian DPP samplers.},
archivePrefix = {arXiv},
arxivId = {1905.00165},
author = {Poulson, Jack},
eprint = {1905.00165},
file = {:Users/ggautier/Documents/Mendeley Desktop/Poulson - 2019 - High-performance sampling of generic Determinantal Point Processes.pdf:pdf},
journal = {ArXiv e-prints},
month = {apr},
title = {{High-performance sampling of generic Determinantal Point Processes}},
url = {http://arxiv.org/abs/1905.00165},
year = {2019}
}
@article{PrWi98,
abstract = {A general problem in computational probability theory is that of generating a random sample from the state space of a Markov chain in accordance with the steady-state probability law of the chain. Another problem is that of generating a random spanning tree of a graph or spanning arborescence of a directed graph in accordance with the uniform distribution, or more generally in accordance with a distribution given by weights on the edges of the graph or digraph. This article gives algorithms for both of these problems, improving on earlier results and exploiting the duality between the two problems. Each of the new algorithms hinges on the recently introduced technique of coupling from the past or on the linked notions of loop-erased random walk and "cycle popping."},
annote = {From Duplicate 2 (How to Get a Perfectly Random Sample from a Generic Markov Chain and Generate a Random Spanning Tree of a Directed Graph - Propp, James Gary; Wilson, David Bruce)

From Duplicate 1 (How to get a perfectly random sample from a generic Markov chain and generate a random spanning tree of a directed graph - Propp, James Gary; Wilson, David Bruce)

From Duplicate 1 (How to get a perfectly random sample from a generic Markov chain and generate a random spanning tree of a directed graph - Propp, J G; Wilson, D B)

NULL

From Duplicate 2 (How to Get a Perfectly Random Sample from a Generic Markov Chain and Generate a Random Spanning Tree of a Directed Graph, , - Propp, James Gary; Wilson, David Bruce)

From Duplicate 1 (How to get a perfectly random sample from a generic Markov chain and generate a random spanning tree of a directed graph - Propp, James Gary; Wilson, David Bruce)

From Duplicate 1 (How to get a perfectly random sample from a generic Markov chain and generate a random spanning tree of a directed graph - Propp, J G; Wilson, D B)

NULL},
author = {Propp, James Gary and Wilson, David Bruce},
doi = {10.1006/JAGM.1997.0917},
file = {:Users/ggautier/Documents/Mendeley Desktop/Propp, Wilson - 1998 - How to Get a Perfectly Random Sample from a Generic Markov Chain and Generate a Random Spanning Tree of a Directe.pdf:pdf},
issn = {0196-6774},
journal = {Journal of Algorithms},
month = {may},
number = {2},
pages = {170--217},
publisher = {Academic Press},
title = {{How to Get a Perfectly Random Sample from a Generic Markov Chain and Generate a Random Spanning Tree of a Directed Graph}},
url = {https://www.sciencedirect.com/science/article/pii/S0196677497909172},
volume = {27},
year = {1998}
}
@book{RaWi06,
abstract = {Regression -- Classification -- Covariance functions -- Model selection and adaptation of hyperparameters -- Relationships between GPs and other models -- Theoretical perspectives -- Approximation methods for large datasets -- Appendix A : Mathematical background -- Appendix B : Guassian Markov processes.},
author = {Rasmussen, Carl Edward. and Williams, Christopher K. I.},
isbn = {026218253X},
pages = {248},
publisher = {MIT Press},
title = {{Gaussian processes for machine learning}},
url = {http://www.gaussianprocess.org/gpml/},
year = {2006}
}
@article{Sos00,
abstract = {The paper contains an exposition of recent as well as old enough results on determinantal random point fields. We start with some general theorems including the proofs of the necessary and sufficient condition for the existence of the determinantal random point field with Hermitian kernel and a criterion for the weak convergence of its distribution. In the second section we proceed with the examples of the determinantal random point fields from Quantum Mechanics, Statistical Mechanics, Random Matrix Theory, Probability Theory, Representation Theory and Ergodic Theory. In connection with the Theory of Renewal Processes we characterize all determinantal random point fields in R{\^{}}1 and Z{\^{}}1 with independent identically distributed spacings. In the third section we study the translation invariant determinantal random point fields and prove the mixing property of any multiplicity and the absolute continuity of the spectra. In the fourth (and the last) section we discuss the proofs of the Central Limit Theorem for the number of particles in the growing box and the Functional Central Limit Theorem for the empirical distribution function of spacings.},
archivePrefix = {arXiv},
arxivId = {math/0002099},
author = {Soshnikov, Alexander},
doi = {10.1070/RM2000v055n05ABEH000321},
eprint = {0002099},
issn = {0042-1316},
journal = {Russian Mathematical Surveys},
month = {feb},
number = {5},
pages = {923--975},
primaryClass = {math},
title = {{Determinantal random point fields}},
url = {http://dx.doi.org/10.1070/RM2000v055n05ABEH000321},
volume = {55},
year = {2000}
}
@inproceedings{TrAmBa17,
abstract = {We present a new random sampling strategy for k-bandlimited signals defined on graphs, based on determinantal point processes (DPP). For small graphs, ie, in cases where the spectrum of the graph is accessible, we exhibit a DPP sampling scheme that enables perfect recovery of bandlimited signals. For large graphs, ie, in cases where the graph's spectrum is not accessible, we investigate, both theoretically and empirically, a sub-optimal but much faster DPP based on loop-erased random walks on the graph. Preliminary experiments show promising results especially in cases where the number of measurements should stay as small as possible and for graphs that have a strong community structure. Our sampling scheme is efficient and can be applied to graphs with up to {\$}10{\^{}}6{\$} nodes.},
archivePrefix = {arXiv},
arxivId = {1703.01594},
author = {Tremblay, Nicolas and Amblard, Pierre-Olivier and Barthelme, Simon},
booktitle = {European Signal Processing Conference (EUSIPCO)},
doi = {10.23919/EUSIPCO.2017.8081494},
eprint = {1703.01594},
isbn = {978-0-9928626-7-1},
month = {aug},
pages = {1674--1678},
publisher = {IEEE},
title = {{Graph sampling with determinantal processes}},
url = {http://ieeexplore.ieee.org/document/8081494/},
year = {2017}
}
@article{TrBaAm18,
abstract = {In this technical report, we discuss several sampling algorithms for Determinantal Point Processes (DPP). DPPs have recently gained a broad interest in the machine learning and statistics literature as random point processes with negative correlation, i.e., ones that can generate a "diverse" sample from a set of items. They are parametrized by a matrix {\$}\backslashmathbf{\{}L{\}}{\$}, called {\$}L{\$}-ensemble, that encodes the correlations between items. The standard sampling algorithm is separated in three phases: 1/{\~{}}eigendecomposition of {\$}\backslashmathbf{\{}L{\}}{\$}, 2/{\~{}}an eigenvector sampling phase where {\$}\backslashmathbf{\{}L{\}}{\$}'s eigenvectors are sampled independently via a Bernoulli variable parametrized by their associated eigenvalue, 3/{\~{}}a Gram-Schmidt-type orthogonalisation procedure of the sampled eigenvectors. In a naive implementation, the computational cost of the third step is on average {\$}\backslashmathcal{\{}O{\}}(N\backslashmu{\^{}}3){\$} where {\$}\backslashmu{\$} is the average number of samples of the DPP. We give an algorithm which runs in {\$}\backslashmathcal{\{}O{\}}(N\backslashmu{\^{}}2){\$} and is extremely simple to implement. If memory is a constraint, we also describe a dual variant with reduced memory costs. In addition, we discuss implementation details often missing in the literature.},
archivePrefix = {arXiv},
arxivId = {1802.08471},
author = {Tremblay, Nicolas and Barthelme, Simon and Amblard, Pierre-Olivier},
eprint = {1802.08471},
journal = {ArXiv e-prints},
keywords = {Computer Science - Learning,Statistics - Computation,Statistics - Machine Learning},
month = {feb},
title = {{Optimized Algorithms to Sample Determinantal Point Processes}},
url = {http://arxiv.org/abs/1802.08471},
year = {2018}
}
@article{Wig67,
abstract = {Introduction. It has been observed repeatedly that von iNeumann made im- portant contributions $\backslash$nto almost all parts of mathematics with the exception of number theory. He had a particular interest},
author = {Wigner, Eugene P.},
doi = {10.1137/1009001},
issn = {0036-1445},
journal = {SIAM Review},
number = {1},
pages = {1--23},
title = {{Random Matrices in Physics}},
volume = {9},
year = {1967}
}
